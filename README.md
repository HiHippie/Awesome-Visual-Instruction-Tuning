# Awesome-Visual-Instruction-Tuning

![cover_img](assets/cover_img.png)

- [Awesome-Visual-Instruction-Tuning](#awesome-visual-instruction-tuning)
  - [Visual Instruction Tuning](#visual-instruction-tuning)
  - [Instruction Tuning](#instruction-tuning)
  - [Awesome Awesomeness](#awesome-awesomeness)


## Visual Instruction Tuning
|  Title  |   Venue  |   Date   |   Code   |   Demo   | Dataset |
|:--------|:--------:|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/lzw-lzw/LEGO.svg?style=social&label=Star) <br> [**LEGO:Language Enhanced Multi-modal Grounding Model**](https://arxiv.org/pdf/2401.06071.pdf)| arXiv | 2024-01-11 | [Github](https://github.com/lzw-lzw/LEGO) | Coming soon | Coming soon |
| [**VILA: On Pre-training for Visual Language Models**](https://arxiv.org/pdf/2312.07533.pdf)| arXiv | 2023-12-12 | - | - | - |
| [**LEGO: Learning EGOcentric Action Frame Generation via Visual Instruction Tuning**](https://arxiv.org/pdf/2312.03849.pdf)| arXiv | 2023-12-06 | - | - | - |
| [**InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language Models**](https://arxiv.org/pdf/2312.01886.pdf)| arXiv | 2023-12-04 | - | - | - |
| ![Star](https://img.shields.io/github/stars/Open3DA/LL3DA.svg?style=social&label=Star) <br> [**LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding, Reasoning, and Planning**](https://arxiv.org/pdf/2311.18651.pdf)| arXiv | 2023-11-30 | [Github](https://github.com/Open3DA/LL3DA) | [Demo](https://ll3da.github.io/) | - |
| [**Continual Instruction Tuning for Large Multimodal Models**](https://arxiv.org/pdf/2311.16206.pdf)| arXiv | 2023-11-27 | - | - | - |
| ![Star](https://img.shields.io/github/stars/lizhaoliu-Lec/CG-VLM.svg?style=social&label=Star) <br> [**Contrastive Vision-Language Alignment Makes Efficient Instruction Learner**](https://arxiv.org/pdf/2311.17945v1.pdf)| arXiv | 2023-11-23 | [Coming soon](https://github.com/lizhaoliu-Lec/CG-VLM) | - | - |
| [**DRESS: Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback**](https://arxiv.org/pdf/2311.10081.pdf)| arXiv | 2023-11-16 | - | - | [Dataset](https://huggingface.co/datasets/YangyiYY/LVLM_NLF) |
| ![Star](https://img.shields.io/github/stars/X2FD/LVIS-INSTRUCT4V.svg?style=social&label=Star) <br> [**To See is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning**](https://arxiv.org/pdf/2311.07574.pdf)| arXiv | 2023-11-13 | [Github](https://github.com/X2FD/LVIS-INSTRUCT4V) | - | [Dataset](https://huggingface.co/datasets/X2FD/LVIS-Instruct4V)  |
| ![Star](https://img.shields.io/github/stars/Luodian/Otter.svg?style=social&label=Star) <br> [**OtterHD: A High-Resolution Multi-modality Model**](http://export.arxiv.org/pdf/2311.04219)| arXiv | 2023-11-07 | [Github](https://github.com/Luodian/Otter) | [Demo](https://huggingface.co/spaces/Otter-AI/OtterHD-Demo) | [Dataset](https://huggingface.co/datasets/Otter-AI/MagnifierBench) |
| ![Star](https://img.shields.io/github/stars/RUCAIBox/ComVint.svg?style=social&label=Star) <br> [**What Makes for Good Visual Instructions? Synthesizing Complex Visual Reasoning Instructions for Visual Instruction Tuning**](https://arxiv.org/pdf/2311.01487.pdf)| arXiv | 2023-11-02 | [Github](https://github.com/RUCAIBox/ComVint) | - | - |
| ![Star](https://img.shields.io/github/stars/liaoning97/REVO-LION.svg?style=social&label=Star) <br> [**REVO-LION: Evaluating and Refining Vision-Language Instruction Tuning Datasets**](https://arxiv.org/pdf/2310.06594.pdf)| arXiv | 2023-10-10 | [Coming soon](https://github.com/liaoning97/REVO-LION) | - | Coming soon |  
| ![Star](https://img.shields.io/github/stars/haotian-liu/LLaVA.svg?style=social&label=Star) <br> [**Improved Baselines with Visual Instruction Tuning**](https://arxiv.org/pdf/2310.03744.pdf) | arXiv | 2023-10-05 | [Github](https://github.com/haotian-liu/LLaVA) | [Demo](https://llava.hliu.cc/) | [Dataset](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) |
|![Star](https://img.shields.io/github/stars/FuxiaoLiu/LRV-Instruction.svg?style=social&label=Star) <br> [**Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning**](https://arxiv.org/pdf/2306.14565.pdf)| arXiv | 2023-09-29 | [Github](https://fuxiaoliu.github.io/LRV/) | [Demo](https://fuxiaoliu.github.io/LRV/) | [Dataset](https://github.com/FuxiaoLiu/LRV-Instruction/blob/main/download.txt#L20) |
| [**An Empirical Study of Scaling Instruct-Tuned Large Multimodal Models**](https://arxiv.org/pdf/2309.09958.pdf)| arXiv | 2023-09-18 | - | - | - |
| ![Star](https://img.shields.io/github/stars/OpenGVLab/LLaMA-Adapter.svg?style=social&label=Star) <br> [**ImageBind-LLM: Multi-modality Instruction Tuning**](https://arxiv.org/pdf/2309.03905.pdf)| arXiv | 2023-09-07 | [Github](https://github.com/OpenGVLab/LLaMA-Adapter/tree/main/imagebind_LLM) | - | - |
| ![Star](https://img.shields.io/github/stars/SALT-NLP/LLaVAR.svg?style=social&label=Star) <br> [**LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding**](https://arxiv.org/pdf/2306.17107.pdf)| arXiv | 2023-06-29 | [Github](https://github.com/SALT-NLP/LLaVAR) | [Demo](https://llavar.github.io/) | [Dataset](https://llavar.github.io/#data) |
| ![Star](https://img.shields.io/github/stars/VT-NLP/MultiInstruct.svg?style=social&label=Star) <br> [**MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning**](https://arxiv.org/pdf/2212.10773.pdf)| ACL 2023 | 2023-06-10 | [Github](https://github.com/VT-NLP/MultiInstruct) | - | - |
|![Star](https://img.shields.io/github/stars/Luodian/Otter.svg?style=social&label=Star) <br> [**MIMIC-IT: Multi-Modal In-Context Instruction Tuning**](https://arxiv.org/pdf/2306.05425.pdf)| arXiv | 2023-06-08 | [Github](https://github.com/Luodian/Otter) | [Demo](https://ottervideo.cliangyu.com/) | - |
| [**M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning**](https://arxiv.org/pdf/2306.04387.pdf)| arXiv | 2023-06-07 | - | [Demo](https://m3-it.github.io/) | [Dataset](https://huggingface.co/datasets/MMInstruction/M3IT) |
| ![Star](https://img.shields.io/github/stars/haotian-liu/LLaVA.svg?style=social&label=Star) <br> [**Visual Instruction Tuning**](https://arxiv.org/pdf/2304.08485.pdf) <br> | NeurIPS 2023, Oral | 2023-04-17 | [Github](https://github.com/haotian-liu/LLaVA) | [Demo](https://llava.hliu.cc/) | [Dataset](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) |
<!-- | ![Star](https://img.shields.io/github/stars/xxx/xxx.svg?style=social&label=Star) <br> [**xxx**]()| arXiv | | [Github]() | [Demo]() | [Dataset]() | -->


## Instruction Tuning
|  Title  |   Venue  |   Date   |   Code   |   Demo   |
|:--------|:--------:|:--------:|:--------:|:--------:|
| ![Star](https://img.shields.io/github/stars/CASIA-LM/MoDS.svg?style=social&label=Star) <br> [**MoDS: Model-oriented Data Selection for Instruction Tuning**](https://arxiv.org/pdf/2311.15653.pdf)| arXiv | 2023-11-27 | [Github](https://github.com/CASIA-LM/MoDS) | - | 
| ![Star](https://img.shields.io/github/stars/PlusLabNLP/Active-IT.svg?style=social&label=Star) <br> [**Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks**](https://arxiv.org/pdf/2311.00288.pdf)| EMNLP 2023 | 2023-11-01 | [Coming soon](https://github.com/PlusLabNLP/Active-IT) | - | 
| [**Distort, Distract, Decode: Instruction-Tuned Model Can Refine its Response from Noisy Instructions**](https://arxiv.org/pdf/2311.00233.pdf)| NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following | 2023-11-01 | - | - | 
| ![Star](https://img.shields.io/github/stars/ChiyuSONG/dynamics-of-instruction-tuning.svg?style=social&label=Star) <br>[**Dynamics of Instruction Tuning: Each Ability of Large Language Models Has Its Own Growth Pace**](https://arxiv.org/pdf/2310.19651.pdf)| arXiv | 2023-10-30 | [Github](https://github.com/ChiyuSONG/dynamics-of-instruction-tuning) | - | 
| ![Star](https://img.shields.io/github/stars/tianyi-lab/Reflection_Tuning.svg?style=social&label=Star) <br> [**Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning**](https://arxiv.org/pdf/2310.11716.pdf)| NeurIPS 2023 Workshop | 2023-10-18 | [Github](https://github.com/tianyi-lab/Reflection_Tuning) | - | 
| [**LoBaSS: Gauging Learnability in Supervised Fine-tuning Data**](https://arxiv.org/pdf/2310.13008.pdf)| arXiv | 2023-10-16 | - | - | 
| [**How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition**](https://arxiv.org/pdf/2310.05492v2.pdf)| arXiv | 2023-10-09 | - | - | 
| ![Star](https://img.shields.io/github/stars/xiaoya-li/Instruction-Tuning-Survey.svg?style=social&label=Star) <br> [**Instruction Tuning for Large Language Models: A Survey**](https://arxiv.org/pdf/2308.10792.pdf)| arXiv | 2023-10-04 | [Github](https://github.com/xiaoya-li/Instruction-Tuning-Survey) | - | 
| ![Star](https://img.shields.io/github/stars/MingLiiii/Cherry_LLM.svg?style=social&label=Star) <br> [**From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning**](https://arxiv.org/pdf/2308.12032.pdf)| arXiv | 2023-08-23 | [Github](https://github.com/MingLiiii/Cherry_LLM) | - |
| ![Star](https://img.shields.io/github/stars/OFA-Sys/InsTag.svg?style=social&label=Star) <br> [**#InsTag: Instruction Tagging for Diversity and Complexity Analysis**](https://arxiv.org/pdf/2308.07074v1.pdf)| arXiv | 2023-08-14 | [Github](https://github.com/OFA-Sys/InsTag) | [Demo](https://www.modelscope.cn/studios/lukeminglkm/instagger_demo/summary) | 
| [**Orca: Progressive Learning from Complex Explanation Traces of GPT-4**](https://arxiv.org/pdf/2306.02707.pdf)| arXiv | 2023-06-05 | - | - | 
| [**LIMA: Less Is More for Alignment**](https://arxiv.org/pdf/2305.11206.pdf)| arXiv | 2023-05-18 | - | - | 
| [**Maybe Only 0.5% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning**](https://arxiv.org/pdf/2305.09246.pdf)| arXiv | 2023-05-16 | - | - | 
| ![Star](https://img.shields.io/github/stars/Instruction-Tuning-with-GPT-4/GPT-4-LLM.svg?style=social&label=Star) <br> [**Instruction Tuning with GPT-4**](https://arxiv.org/pdf/2304.03277.pdf)| arXiv | 2023-04-06 | [Github](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | [Demo](https://instruction-tuning-with-gpt-4.github.io/) | 
| ![Star](https://img.shields.io/github/stars/google-research/FLAN.svg?style=social&label=Star) <br> [**The Flan Collection: Designing Data and Methods for Effective Instruction Tuning**](https://arxiv.org/pdf/2301.13688.pdf)| arXiv | 2023-01-31 | [Github](https://github.com/google-research/FLAN/tree/main/flan/v2) | - | 
| ![Star](https://img.shields.io/github/stars/allenai/open-instruct.svg?style=social&label=Star) <br> [**How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources**](https://arxiv.org/pdf/2306.04751.pdf)| NeurIPS 2023 | 2023-01-07 | [Github](https://github.com/allenai/open-instruct) | - | 
| ![Star](https://img.shields.io/github/stars/yizhongw/self-instruct.svg?style=social&label=Star) <br> [**Self-Instruct: Aligning Language Models with Self-Generated Instructions**](https://arxiv.org/pdf/2212.10560.pdf)| ACL 2023 | 2022-12-20 | [Github](https://github.com/yizhongw/self-instruct) | - | 
| [**Scaling Instruction-Finetuned Language Models**](https://arxiv.org/pdf/2210.11416.pdf)| arXiv | 2022-10-20 | - | - | 
<!-- | ![Star](https://img.shields.io/github/stars/xxx/xxx.svg?style=social&label=Star) <br> [**xxx**]()| arXiv | | [Github]() | [Demo]() |  -->



## Awesome Awesomeness

|  Repositories  | Stars |
|:--------|:--------|
|[**Awesome-LLM-Survey**](https://github.com/HqWu-HITCS/Awesome-LLM-Survey)|![Star](https://img.shields.io/github/stars/HqWu-HITCS/Awesome-LLM-Survey.svg?style=social&label=Star) |
| [**Instruction-Tuning-Papers**](https://github.com/SinclairCoder/Instruction-Tuning-Papers) | ![Star](https://img.shields.io/github/stars/SinclairCoder/Instruction-Tuning-Papers.svg?style=social&label=Star) |